{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, optimizers, Sequential, datasets, losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前向传播"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BN 层的输入记作 $x$, 输出记作 $\\tilde{x}$\n",
    "\n",
    "$$\\tilde{x}_{train}=\\frac{x_{train}-\\mu_B}{\\sqrt{\\sigma^2_B + \\epsilon}} . \\gamma + \\beta$$\n",
    "\n",
    "对于全局训练数据的统计值为：\n",
    "\n",
    "$$\\mu_r=moment.\\mu_r+(1-moment).\\mu_B $$\n",
    "\n",
    "$$\\sigma^2_r=moment.\\sigma^2_r+(1-moment).\\sigma^2_B $$\n",
    "\n",
    "TF 中 momenttum 为超参，默认为 0.99\n",
    "\n",
    "测试阶段\n",
    "\n",
    "**变量值均来自训练阶段统计或优化的结果**，在测试阶段直接使用，不用更新\n",
    "\n",
    "$$\\tilde{x}_{test}=\\frac{x_{test}-\\mu_r}{\\sqrt{\\sigma^2_r + \\epsilon}} . \\gamma + \\beta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BN 层在测试与训练阶段的行为不同，需通过 training 标志位来区分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据的前处理模块\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "# 划分子集的个数\n",
    "batchsz = 128\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_db = train_db.map(preprocess).shuffle(10000).batch(batchsz)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_db = test_db.map(preprocess).batch(batchsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF 中，可直接实现 BN 层\n",
    "# layer = layers.BatchNormalization()\n",
    "model = Sequential([\n",
    "    # 个数 6 ，尺寸 3×3\n",
    "    layers.Conv2D(6, kernel_size=3, strides=1),\n",
    "    # 添加 BN 层\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "    layers.ReLU(),\n",
    "    \n",
    "    layers.Conv2D(16, kernel_size=3, strides=1),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    layers.Dense(84, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "model.build(input_shape=(None, 32, 32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 6)         60        \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 30, 30, 6)         24        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 15, 15, 6)         0         \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 15, 15, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 13, 13, 16)        880       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 13, 13, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 120)               69240     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 81,282\n",
      "Trainable params: 81,238\n",
      "Non-trainable params: 44\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.SGD(lr=1e-2)\n",
    "for x,y in train_db:\n",
    "    with tf.GradientTape() as tape:\n",
    "        x = tf.expand_dims(x, axis=3)\n",
    "        out = model(x, training=True)\n",
    "        y_onehot = tf.one_hot(y, depth=10)\n",
    "        loss = tf.reduce_mean(losses.categorical_crossentropy(y_onehot, out))\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        # for x,y in test_db:\n",
    "        #     x = tf.expand_dims(x, axis=3)\n",
    "        #     out = model(x, training=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
