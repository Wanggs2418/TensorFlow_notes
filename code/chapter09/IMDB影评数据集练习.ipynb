{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, datasets, optimizers, losses\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据的预处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始数据设置并加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsz = 100\n",
    "shuffles = 1000\n",
    "# 词汇表大小\n",
    "total_words = 10000\n",
    "# 句子最大长度\n",
    "max_review_len = 80\n",
    "# 词向量特征长度\n",
    "embedding_len = 100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=total_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度信息显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 长度为 25000 的一维数组，每个元素的长度不定,存储的是相关单词的索引\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "print(x_train[0])\n",
    "print(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据处理，设置最大截断长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置截断\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n",
    "\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# drop_remainder=True 参数设置丢弃最后一个batch,因为实际的batch小于预设的\n",
    "db_train = db_train.shuffle(shuffles).batch(batchsz, drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.batch(batchsz, drop_remainder=True)\n",
    "\n",
    "\n",
    "# print(y_train)\n",
    "# 'word':index\n",
    "word_index = datasets.imdb.get_word_index()\n",
    "# print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 长度为 25000 的一维数组，每个元素的长度不定,存储的是相关单词的索引\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加4个标志位\n",
    "word_index = {k:(v+3) for k, v in word_index.items()}\n",
    "word_index['<PAD>'] = 0\n",
    "word_index['<STAR>'] = 1\n",
    "word_index['<UNK>'] = 2\n",
    "word_index['<UNUSED>'] = 3\n",
    "index_to_word = {value:key for key, value in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数字编码的句子转换位句子\n",
    "def num_to_sentence(num):\n",
    "    return ' '.join([index_to_word.get(i, '?') for i in num])\n",
    "# num_to_sentence(x_train[9])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络模型的创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class demoRNN(keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(demoRNN, self).__init__()\n",
    "        # [b, 64],Cell 初始化状态向量 h0\n",
    "        self.state0 = [tf.zeros([batchsz, units])]\n",
    "        self.state1 = [tf.zeros([batchsz, units])]\n",
    "        # [b, 80]=>[b, 80, 100] input_dims, output_dims, max_review_len\n",
    "        self.embedding = layers.Embedding(total_words, embedding_len, input_length=max_review_len)\n",
    "        self.rnn_cell0 = layers.SimpleRNNCell(units, dropout=0.5)\n",
    "        self.rnn_cell1 = layers.SimpleRNNCell(units, dropout=0.5)\n",
    "        # 二分类\n",
    "        # [b, 80, 100]=>[b, 64]=>[b,1]\n",
    "        # self.outlayer = layers.Dense(1)\n",
    "        self.outlayers = keras.Sequential([\n",
    "            layers.Dense(units),\n",
    "            layers.Dropout(rate=0.5),\n",
    "            layers.ReLU(),\n",
    "            layers.Dense(1)\n",
    "        ])\n",
    "    def call(self, inputs, training=None):\n",
    "        # [b,80]\n",
    "        x = inputs\n",
    "        # [b,80]=>[b,80,100]\n",
    "        x = self.embedding(x)\n",
    "        # 通过 2 个 RNN cell,[b,80,100]=>[b,64]\n",
    "        state0 = self.state0\n",
    "        state1 = self.state1\n",
    "        # [b,80,100]=>[b,100]\n",
    "        for word in tf.unstack(x, axis=1):\n",
    "            out0, state0 = self.rnn_cell0(word, state0, training)\n",
    "            out1, state1 = self.rnn_cell1(out0, state1, training)\n",
    "        x = self.outlayers(out1, training)\n",
    "        prob = tf.sigmoid(x)\n",
    "        return prob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 64\n",
    "epochs =60\n",
    "    # 创建模型\n",
    "model = demoRNN(units)\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001),loss=losses.binary_crossentropy, metrics=['accuracy'])\n",
    "history = model.fit(db_train, epochs=epochs, validation_data=db_test)\n",
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accuracy = history.history['val_accuracy']\n",
    "all_loss = history.history['val_loss']\n",
    "plt.plot(range(1, len(all_accuracy)+1), all_accuracy)\n",
    "plt.plot(range(1, len(all_loss)+1), all_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度裁剪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4.923814   0.08684337]\n",
      " [4.3033166  3.6082268 ]], shape=(2, 2), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[3.2960672 , 0.05813412],\n",
       "       [2.8806982 , 2.4153957 ]], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform([2,2])*5\n",
    "print(a)\n",
    "tf.clip_by_norm(a, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4.087775, shape=(), dtype=float32) tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.random.normal([3,3])\n",
    "w2 = tf.random.normal([3,3])\n",
    "# 返回两个参数:张量 List 和 global_norm(裁剪前的梯度总范数和), max norm =2\n",
    "(ww1, ww2), global_norm = tf.clip_by_global_norm([w1, w2], 2)\n",
    "global_norm2 = tf.math.sqrt(tf.norm(ww1)**2+tf.norm(ww2)**2)\n",
    "print(global_norm, global_norm2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
