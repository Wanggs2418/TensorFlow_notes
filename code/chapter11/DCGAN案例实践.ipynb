{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "from    tensorflow.keras import layers, Model, losses\n",
    "from dataset import make_anime_dataset\n",
    "# from scipy.misc import toimage \n",
    "# misc模块在 1.10.0弃用，会在2.0.0完全废除，用image.fromarray()代替\n",
    "from PIL import Image #Python Image Library\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由 5 个转置卷积层组成，实现特征图高宽的放大，特征图通道层层减少。\n",
    "\n",
    "- 将长度为 100 的隐藏变量 $z$ 变换为 [b, 1, 1, 100]\n",
    "- 依次通过转置卷积层，放大高宽维度，减少通道维度，最后高宽为 64×64，通道为 3\n",
    "- 每个卷积层中插入 BN 层提高训练稳定性，卷积层选择不使用偏置向量"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/01.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成器网络类\n",
    "class Generator(keras.Model):\n",
    "    # [b, 100] => [b, 64, 64, 3]\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        filter = 64\n",
    "        # 输出 channel 为 filter*8,核大小为4， 步长为1，不使用padding和偏置\n",
    "        self.conv1 = layers.Conv2DTranspose(filter*8, 4, 1, 'valid', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "\n",
    "        self.conv2 = layers.Conv2DTranspose(filter*4, 4, 2, 'same', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        # 转置卷积层3\n",
    "        self.conv3 = layers.Conv2DTranspose(filter*2, 4,2, 'same', use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        # 转置卷积层4\n",
    "        self.conv4 = layers.Conv2DTranspose(filter*1, 4,2, 'same', use_bias=False)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        # 转置卷积层5\n",
    "        self.conv5 = layers.Conv2DTranspose(3, 4,2, 'same', use_bias=False)\n",
    "    # \n",
    "    def call(self, inputs, training = None):\n",
    "        # [z, 100]\n",
    "        x = inputs\n",
    "        # [b, 1, 1, 100]\n",
    "        # x = tf.reshape(x, (-1, 1, 1, x.shape[1]))\n",
    "        x = tf.reshape(x, (x.shape[0], 1, 1, x.shape[1]))\n",
    "        # 激活函数\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = tf.nn.relu(self.bn1(self.conv1(x), training=training))\n",
    "        x = tf.nn.relu(self.bn2(self.conv2(x), training=training))\n",
    "        x = tf.nn.relu(self.bn3(self.conv3(x), training=training))\n",
    "        x = tf.nn.relu(self.bn4(self.conv4(x), training=training))\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        # 输出范围 -1~1\n",
    "        x = tf.tanh(x)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类器，普通意义上的分类网络\n",
    "class Discriminator(Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        filter = 64\n",
    "        # [b, 64, 64, 3]=>[b, 1]\n",
    "        # filter:64, kernek:5, stride:3\n",
    "        self.conv1 = layers.Conv2D(filter, 4, 2, 'valid', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        # 使得GAN training 更加稳定\n",
    "        self.conv2 = layers.Conv2D(filter*2, 4, 2, 'valid', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "\n",
    "        self.conv3 = layers.Conv2D(filter*4, 4, 2, 'valid', use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "\n",
    "        self.conv4 = layers.Conv2D(filter*8, 3, 1, 'valid', use_bias=False)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv5 = layers.Conv2D(filter*16, 3, 1, 'valid', use_bias=False)\n",
    "        self.bn5 = layers.BatchNormalization()\n",
    "\n",
    "        # 全局池化层\n",
    "        self.pool = layers.GlobalAveragePooling2D()\n",
    "        # 特征打平\n",
    "        self.flatten = layers.Flatten()\n",
    "        # 全连接层分类\n",
    "        self.fc = layers.Dense(1)\n",
    "\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        # (4, 31, 31, 64)\n",
    "        x = tf.nn.leaky_relu(self.bn1(self.conv1(inputs), training=training))\n",
    "        # (4, 14, 14, 128)\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "        # (4, 6, 6, 256)\n",
    "        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))\n",
    "        # (4, 4, 4, 512)\n",
    "        x = tf.nn.leaky_relu(self.bn4(self.conv4(x), training=training))\n",
    "        # 卷积-BN-激活函数:(4, 2, 2, 1024)\n",
    "        x = tf.nn.leaky_relu(self.bn5(self.conv5(x), training=training))\n",
    "        # 卷积-BN-激活函数:(4, 1024)\n",
    "        x = self.pool(x)\n",
    "        # 打平\n",
    "        x = self.flatten(x)\n",
    "        # 输出，[b, 1024] => [b, 1]\n",
    "        logits = self.fc(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将多张照片合并,辅助函数\n",
    "def save_result(val_out, val_block_size, image_path, color_mode):\n",
    "    def preprocess(img):\n",
    "        img = ((img + 1.0) * 127.5).astype(np.uint8)\n",
    "        # img = img.astype(np.uint8)\n",
    "        return img\n",
    "\n",
    "    preprocesed = preprocess(val_out)\n",
    "    final_image = np.array([])\n",
    "    single_row = np.array([])\n",
    "    for b in range(val_out.shape[0]):\n",
    "        # concat image into a row\n",
    "        if single_row.size == 0:\n",
    "            single_row = preprocesed[b, :, :, :]\n",
    "        else:\n",
    "            single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=1)\n",
    "\n",
    "        # concat image row to final_image\n",
    "        if (b+1) % val_block_size == 0:\n",
    "            if final_image.size == 0:\n",
    "                final_image = single_row\n",
    "            else:\n",
    "                final_image = np.concatenate((final_image, single_row), axis=0)\n",
    "\n",
    "            # reset single row\n",
    "            single_row = np.array([])\n",
    "\n",
    "    if final_image.shape[2] == 1:\n",
    "        final_image = np.squeeze(final_image, axis=2)\n",
    "    Image.fromarray(final_image).save(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def celoss_ones(logits):\n",
    "    \"\"\"\n",
    "    计算与标签1的交叉熵CE\n",
    "    \"\"\"\n",
    "    y = tf.ones_like(logits)\n",
    "    loss = losses.binary_crossentropy(y, logits, from_logits=True)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def celoss_zeros(logits):\n",
    "    \"\"\"\n",
    "    计算与标签1的交叉熵CE\n",
    "    \"\"\"\n",
    "    y = tf.zeros_like(logits)\n",
    "    loss = losses.binary_crossentropy(y, logits, from_logits=True)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判别器的损失函数\n",
    "def d_loss_fn(generator, discriminator, batch_z, batch_x, is_training):\n",
    "    # 采样生成图片\n",
    "    fake_image = generator(batch_z, is_training)\n",
    "    # 判别\n",
    "    d_fake_logits = discriminator(fake_image, is_training)\n",
    "    d_real_logits = discriminator(batch_x, is_training)\n",
    "    # 误差计算,判别器希望真的都判别为真，假的都分辨出为假。\n",
    "    # 真实值与 1 的损失最小，假的与0的损失最小，最终损失为二者之和\n",
    "    d_loss_real = celoss_ones(d_real_logits)\n",
    "    d_loss_fake = celoss_zeros(d_fake_logits)\n",
    "\n",
    "    # 合并误差\n",
    "    loss = d_loss_fake + d_loss_real\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成器的损失函数\n",
    "def g_loss_fn(generator, discriminator, batch_z, is_training):\n",
    "    fake_image = generator(batch_z, is_training)\n",
    "    d_fake_logits = discriminator(fake_image, is_training)\n",
    "    # 假的图片希望尽可能接近1，即真实图片\n",
    "    loss = celoss_ones(d_fake_logits)\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处利用直接编写好的 `make_anime_dataset` 函数\n",
    "\n",
    "共21551张图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: (64, 64, 64, 3), types: tf.float32> (64, 64, 3)\n",
      "(64, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子，方便复现\n",
    "tf.random.set_seed(22)\n",
    "batch_size = 64\n",
    "z_dim = 100\n",
    "epochs = 1000000\n",
    "lr = 2e3\n",
    "is_training = True\n",
    "# 判别器训练5次后，生成器训练1次\n",
    "k =5 \n",
    "# 设置本地数据集路径\n",
    "img_path = glob.glob(r'E:\\GAN_training_datasets\\archive\\data\\*.png')\n",
    "# print('images num:', len(img_path))\n",
    "dataset, img_shape, _ = make_anime_dataset(img_path, batch_size, resize=64)\n",
    "print(dataset, img_shape)\n",
    "# 获取第一个样本\n",
    "sample = next(iter(dataset))\n",
    "print(sample.shape)\n",
    "\n",
    "dataset = dataset.repeat(100)\n",
    "db_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成器\n",
    "generator = Generator()\n",
    "# generator.build(input_shape=(None, z_dim))\n",
    "generator.build(input_shape=(4, z_dim))\n",
    "\n",
    "\n",
    "discriminator = Discriminator()\n",
    "# discriminator.build(input_shape=(None, 64, 64, 3))\n",
    "discriminator.build(input_shape=(4, 64, 64, 3))\n",
    "\n",
    "# 分别创建优化器\n",
    "g_optimizer = tf.optimizers.Adam(learning_rate=lr, beta_1=0.5)\n",
    "d_optimizer = tf.optimizers.Adam(learning_rate=lr, beta_1=0.5)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batch_z = tf.random.uniform([batch_size, z_dim], minval=-1., maxval=1.)\n",
    "    batch_x = next(db_iter)\n",
    "\n",
    "    # 1.设定判别训练5次后，生成器训练1次\n",
    "    # train D,判别器损失函数，希望能够完全判别，1判别的都是真，0判别的都是假\n",
    "    for _ in range(k):\n",
    "        with tf.GradientTape() as tape:\n",
    "            d_loss = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n",
    "        grads = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "        d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "\n",
    "    # 2.train G，生成器损失函数，希望生成接近真实照片 1 ，即计算与1的损失\n",
    "    with tf.GradientTape() as tape:\n",
    "        g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)\n",
    "    grads = tape.gradient(g_loss, generator.trainable_variables)\n",
    "    g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, 'd_loss', float(d_loss), 'g-loss', float(g_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f78ddee4002e2dfa246288d7c1d26ecb3f2a097ed0e0d4db73148b3465835f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
