{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"7f78ddee4002e2dfa246288d7c1d26ecb3f2a097ed0e0d4db73148b3465835f1"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import  tensorflow as tf\nfrom    tensorflow import keras\nfrom    tensorflow.keras import layers, Model, losses\n# from dataset import make_anime_dataset\n# from scipy.misc import toimage \n# misc模块在 1.10.0弃用，会在2.0.0完全废除，用image.fromarray()代替\nfrom PIL import Image #Python Image Library\nimport glob\nimport numpy as np\nimport multiprocessing","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:10:26.771262Z","iopub.execute_input":"2023-04-09T11:10:26.771791Z","iopub.status.idle":"2023-04-09T11:10:26.779555Z","shell.execute_reply.started":"2023-04-09T11:10:26.771748Z","shell.execute_reply":"2023-04-09T11:10:26.778400Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# 引用的自定义函数库\ndef make_anime_dataset(img_paths, batch_size, resize=64, drop_remainder=True, shuffle=True, repeat=1):\n\n    # @tf.function\n    def _map_fn(img):\n        img = tf.image.resize(img, [resize, resize])\n        # img = tf.image.random_crop(img,[resize, resize])\n        # img = tf.image.random_flip_left_right(img)\n        # img = tf.image.random_flip_up_down(img)\n        img = tf.clip_by_value(img, 0, 255)\n        img = img / 127.5 - 1 #-1~1\n        return img\n\n    dataset = disk_image_batch_dataset(img_paths,\n                                          batch_size,\n                                          drop_remainder=drop_remainder,\n                                          map_fn=_map_fn,\n                                          shuffle=shuffle,\n                                          repeat=repeat)\n    img_shape = (resize, resize, 3)\n    len_dataset = len(img_paths) // batch_size\n\n    return dataset, img_shape, len_dataset\n\n\ndef batch_dataset(dataset,\n                  batch_size,\n                  drop_remainder=True,\n                  n_prefetch_batch=1,\n                  filter_fn=None,\n                  map_fn=None,\n                  n_map_threads=None,\n                  filter_after_map=False,\n                  shuffle=True,\n                  shuffle_buffer_size=None,\n                  repeat=None):\n    # set defaults\n    if n_map_threads is None:\n        n_map_threads = multiprocessing.cpu_count()\n    if shuffle and shuffle_buffer_size is None:\n        shuffle_buffer_size = max(batch_size * 128, 2048)  # set the minimum buffer size as 2048\n\n    # [*] it is efficient to conduct `shuffle` before `map`/`filter` because `map`/`filter` is sometimes costly\n    if shuffle:\n        dataset = dataset.shuffle(shuffle_buffer_size)\n\n    if not filter_after_map:\n        if filter_fn:\n            dataset = dataset.filter(filter_fn)\n\n        if map_fn:\n            dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads)\n\n    else:  # [*] this is slower\n        if map_fn:\n            dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads)\n\n        if filter_fn:\n            dataset = dataset.filter(filter_fn)\n\n    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n\n    dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch)\n\n    return dataset\n\n\ndef memory_data_batch_dataset(memory_data,\n                              batch_size,\n                              drop_remainder=True,\n                              n_prefetch_batch=1,\n                              filter_fn=None,\n                              map_fn=None,\n                              n_map_threads=None,\n                              filter_after_map=False,\n                              shuffle=True,\n                              shuffle_buffer_size=None,\n                              repeat=None):\n    \"\"\"Batch dataset of memory data.\n\n    Parameters\n    ----------\n    memory_data : nested structure of tensors/ndarrays/lists\n\n    \"\"\"\n    dataset = tf.data.Dataset.from_tensor_slices(memory_data)\n    dataset = batch_dataset(dataset,\n                            batch_size,\n                            drop_remainder=drop_remainder,\n                            n_prefetch_batch=n_prefetch_batch,\n                            filter_fn=filter_fn,\n                            map_fn=map_fn,\n                            n_map_threads=n_map_threads,\n                            filter_after_map=filter_after_map,\n                            shuffle=shuffle,\n                            shuffle_buffer_size=shuffle_buffer_size,\n                            repeat=repeat)\n    return dataset\n\n\ndef disk_image_batch_dataset(img_paths,\n                             batch_size,\n                             labels=None,\n                             drop_remainder=True,\n                             n_prefetch_batch=1,\n                             filter_fn=None,\n                             map_fn=None,\n                             n_map_threads=None,\n                             filter_after_map=False,\n                             shuffle=True,\n                             shuffle_buffer_size=None,\n                             repeat=None):\n    \"\"\"Batch dataset of disk image for PNG and JPEG.\n\n    Parameters\n    ----------\n        img_paths : 1d-tensor/ndarray/list of str\n        labels : nested structure of tensors/ndarrays/lists\n\n    \"\"\"\n    if labels is None:\n        memory_data = img_paths\n    else:\n        memory_data = (img_paths, labels)\n\n    def parse_fn(path, *label):\n        img = tf.io.read_file(path)\n        img = tf.image.decode_jpeg(img, channels=3)  # fix channels to 3\n        return (img,) + label\n\n    if map_fn:  # fuse `map_fn` and `parse_fn`\n        def map_fn_(*args):\n            return map_fn(*parse_fn(*args))\n    else:\n        map_fn_ = parse_fn\n\n    dataset = memory_data_batch_dataset(memory_data,\n                                        batch_size,\n                                        drop_remainder=drop_remainder,\n                                        n_prefetch_batch=n_prefetch_batch,\n                                        filter_fn=filter_fn,\n                                        map_fn=map_fn_,\n                                        n_map_threads=n_map_threads,\n                                        filter_after_map=filter_after_map,\n                                        shuffle=shuffle,\n                                        shuffle_buffer_size=shuffle_buffer_size,\n                                        repeat=repeat)\n\n    return dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:10:26.781931Z","iopub.execute_input":"2023-04-09T11:10:26.782296Z","iopub.status.idle":"2023-04-09T11:10:26.803007Z","shell.execute_reply.started":"2023-04-09T11:10:26.782259Z","shell.execute_reply":"2023-04-09T11:10:26.801966Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"由 5 个转置卷积层组成，实现特征图高宽的放大，特征图通道层层减少。\n\n- 将长度为 100 的隐藏变量 $z$ 变换为 [b, 1, 1, 100]\n- 依次通过转置卷积层，放大高宽维度，减少通道维度，最后高宽为 64×64，通道为 3\n- 每个卷积层中插入 BN 层提高训练稳定性，卷积层选择不使用偏置向量","metadata":{}},{"cell_type":"code","source":"# 生成器网络类\nclass Generator(keras.Model):\n    # [b, 100] => [b, 64, 64, 3]\n    \n    def __init__(self):\n        super(Generator, self).__init__()\n        filter = 64\n        # 输出 channel 为 filter*8,核大小为4， 步长为1，不使用padding和偏置\n        self.conv1 = layers.Conv2DTranspose(filter*8, 4, 1, 'valid', use_bias=False)\n        self.bn1 = layers.BatchNormalization()\n\n        self.conv2 = layers.Conv2DTranspose(filter*4, 4, 2, 'same', use_bias=False)\n        self.bn2 = layers.BatchNormalization()\n        # 转置卷积层3\n        self.conv3 = layers.Conv2DTranspose(filter*2, 4,2, 'same', use_bias=False)\n        self.bn3 = layers.BatchNormalization()\n        # 转置卷积层4\n        self.conv4 = layers.Conv2DTranspose(filter*1, 4,2, 'same', use_bias=False)\n        self.bn4 = layers.BatchNormalization()\n        # 转置卷积层5\n        self.conv5 = layers.Conv2DTranspose(3, 4,2, 'same', use_bias=False)\n    # \n    def call(self, inputs, training = None):\n        # [z, 100]\n        x = inputs\n        # [b, 1, 1, 100]\n        # x = tf.reshape(x, (-1, 1, 1, x.shape[1]))\n        x = tf.reshape(x, (x.shape[0], 1, 1, x.shape[1]))\n        # 激活函数\n        x = tf.nn.relu(x)\n        \n        x = tf.nn.relu(self.bn1(self.conv1(x), training=training))\n        x = tf.nn.relu(self.bn2(self.conv2(x), training=training))\n        x = tf.nn.relu(self.bn3(self.conv3(x), training=training))\n        x = tf.nn.relu(self.bn4(self.conv4(x), training=training))\n\n        x = self.conv5(x)\n        # 输出范围 -1~1\n        x = tf.tanh(x)\n\n        return x\n        ","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:10:26.806430Z","iopub.execute_input":"2023-04-09T11:10:26.807327Z","iopub.status.idle":"2023-04-09T11:10:26.818967Z","shell.execute_reply.started":"2023-04-09T11:10:26.807288Z","shell.execute_reply":"2023-04-09T11:10:26.818006Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# 分类器，普通意义上的分类网络\nclass Discriminator(Model):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        filter = 64\n        # [b, 64, 64, 3]=>[b, 1]\n        # filter:64, kernek:5, stride:3\n        self.conv1 = layers.Conv2D(filter, 4, 2, 'valid', use_bias=False)\n        self.bn1 = layers.BatchNormalization()\n        # 使得GAN training 更加稳定\n        self.conv2 = layers.Conv2D(filter*2, 4, 2, 'valid', use_bias=False)\n        self.bn2 = layers.BatchNormalization()\n\n        self.conv3 = layers.Conv2D(filter*4, 4, 2, 'valid', use_bias=False)\n        self.bn3 = layers.BatchNormalization()\n\n        self.conv4 = layers.Conv2D(filter*8, 3, 1, 'valid', use_bias=False)\n        self.bn4 = layers.BatchNormalization()\n        \n        self.conv5 = layers.Conv2D(filter*16, 3, 1, 'valid', use_bias=False)\n        self.bn5 = layers.BatchNormalization()\n\n        # 全局池化层\n        self.pool = layers.GlobalAveragePooling2D()\n        # 特征打平\n        self.flatten = layers.Flatten()\n        # 全连接层分类\n        self.fc = layers.Dense(1)\n\n    \n    def call(self, inputs, training=None):\n        # (4, 31, 31, 64)\n        x = tf.nn.leaky_relu(self.bn1(self.conv1(inputs), training=training))\n        # (4, 14, 14, 128)\n        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n        # (4, 6, 6, 256)\n        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))\n        # (4, 4, 4, 512)\n        x = tf.nn.leaky_relu(self.bn4(self.conv4(x), training=training))\n        # 卷积-BN-激活函数:(4, 2, 2, 1024)\n        x = tf.nn.leaky_relu(self.bn5(self.conv5(x), training=training))\n        # 卷积-BN-激活函数:(4, 1024)\n        x = self.pool(x)\n        # 打平\n        x = self.flatten(x)\n        # 输出，[b, 1024] => [b, 1]\n        logits = self.fc(x)\n\n        return logits","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:10:26.821073Z","iopub.execute_input":"2023-04-09T11:10:26.821749Z","iopub.status.idle":"2023-04-09T11:10:26.834580Z","shell.execute_reply.started":"2023-04-09T11:10:26.821714Z","shell.execute_reply":"2023-04-09T11:10:26.833626Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### 训练","metadata":{}},{"cell_type":"code","source":"# 将多张照片合并,辅助函数\ndef save_result(val_out, val_block_size, image_path, color_mode):\n    def preprocess(img):\n        img = ((img + 1.0) * 127.5).astype(np.uint8)\n        # img = img.astype(np.uint8)\n        return img\n\n    preprocesed = preprocess(val_out)\n    final_image = np.array([])\n    single_row = np.array([])\n    for b in range(val_out.shape[0]):\n        # concat image into a row\n        if single_row.size == 0:\n            single_row = preprocesed[b, :, :, :]\n        else:\n            single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=1)\n\n        # concat image row to final_image\n        if (b+1) % val_block_size == 0:\n            if final_image.size == 0:\n                final_image = single_row\n            else:\n                final_image = np.concatenate((final_image, single_row), axis=0)\n\n            # reset single row\n            single_row = np.array([])\n\n    if final_image.shape[2] == 1:\n        final_image = np.squeeze(final_image, axis=2)\n    Image.fromarray(final_image).save(image_path)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:10:26.893234Z","iopub.execute_input":"2023-04-09T11:10:26.893671Z","iopub.status.idle":"2023-04-09T11:10:26.902804Z","shell.execute_reply.started":"2023-04-09T11:10:26.893631Z","shell.execute_reply":"2023-04-09T11:10:26.901640Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def celoss_ones(logits):\n    \"\"\"\n    计算与标签1的交叉熵CE\n    \"\"\"\n    y = tf.ones_like(logits)\n    loss = losses.binary_crossentropy(y, logits, from_logits=True)\n    return tf.reduce_mean(loss)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:10:26.905289Z","iopub.execute_input":"2023-04-09T11:10:26.905845Z","iopub.status.idle":"2023-04-09T11:10:26.914969Z","shell.execute_reply.started":"2023-04-09T11:10:26.905810Z","shell.execute_reply":"2023-04-09T11:10:26.913971Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def celoss_zeros(logits):\n    \"\"\"\n    计算与标签1的交叉熵CE\n    \"\"\"\n    y = tf.zeros_like(logits)\n    loss = losses.binary_crossentropy(y, logits, from_logits=True)\n    return tf.reduce_mean(loss)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:10:26.916372Z","iopub.execute_input":"2023-04-09T11:10:26.917308Z","iopub.status.idle":"2023-04-09T11:10:26.924187Z","shell.execute_reply.started":"2023-04-09T11:10:26.917263Z","shell.execute_reply":"2023-04-09T11:10:26.923201Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# 判别器的损失函数\ndef d_loss_fn(generator, discriminator, batch_z, batch_x, is_training):\n    # 采样生成图片\n    fake_image = generator(batch_z, is_training)\n    # 判别\n    d_fake_logits = discriminator(fake_image, is_training)\n    d_real_logits = discriminator(batch_x, is_training)\n    # 误差计算,判别器希望真的都判别为真，假的都分辨出为假。\n    # 真实值与 1 的损失最小，假的与0的损失最小，最终损失为二者之和\n    d_loss_real = celoss_ones(d_real_logits)\n    d_loss_fake = celoss_zeros(d_fake_logits)\n\n    # 合并误差\n    loss = d_loss_fake + d_loss_real\n    return loss","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:10:26.925597Z","iopub.execute_input":"2023-04-09T11:10:26.926542Z","iopub.status.idle":"2023-04-09T11:10:26.934213Z","shell.execute_reply.started":"2023-04-09T11:10:26.926502Z","shell.execute_reply":"2023-04-09T11:10:26.933278Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# 生成器的损失函数\ndef g_loss_fn(generator, discriminator, batch_z, is_training):\n    fake_image = generator(batch_z, is_training)\n    d_fake_logits = discriminator(fake_image, is_training)\n    # 假的图片希望尽可能接近1，即真实图片\n    loss = celoss_ones(d_fake_logits)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:10:26.936871Z","iopub.execute_input":"2023-04-09T11:10:26.937703Z","iopub.status.idle":"2023-04-09T11:10:26.946505Z","shell.execute_reply.started":"2023-04-09T11:10:26.937668Z","shell.execute_reply":"2023-04-09T11:10:26.945515Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"此处利用直接编写好的 `make_anime_dataset` 函数\n\n共21551张图片","metadata":{}},{"cell_type":"code","source":"# 设置随机种子，方便复现\ntf.random.set_seed(22)\nbatch_size = 64\nz_dim = 100\nepochs = 1000000\nlr = 2e3\nis_training = True\n# 判别器训练5次后，生成器训练1次\nk =5 \n# 设置本地数据集路径\n# \"/kaggle/input/anime-faces/data/data/*\"\nimg_path = glob.glob(\"/kaggle/input/anime-faces/data/data/*\")\n# print('images num:', len(img_path))\ndataset, img_shape, _ = make_anime_dataset(img_path, batch_size, resize=64)\nprint(dataset, img_shape)\n# 获取第一个样本\nsample = next(iter(dataset))\nprint(sample.shape)\n\ndataset = dataset.repeat(100)\ndb_iter = iter(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:10:26.947925Z","iopub.execute_input":"2023-04-09T11:10:26.948689Z","iopub.status.idle":"2023-04-09T11:10:30.432257Z","shell.execute_reply.started":"2023-04-09T11:10:26.948655Z","shell.execute_reply":"2023-04-09T11:10:30.430604Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"<PrefetchDataset element_spec=TensorSpec(shape=(64, 64, 64, 3), dtype=tf.float32, name=None)> (64, 64, 3)\n(64, 64, 64, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"# 生成器\ngenerator = Generator()\n# generator.build(input_shape=(None, z_dim))\ngenerator.build(input_shape=(4, z_dim))\n\n\ndiscriminator = Discriminator()\n# discriminator.build(input_shape=(None, 64, 64, 3))\ndiscriminator.build(input_shape=(4, 64, 64, 3))\n\n# 分别创建优化器\ng_optimizer = tf.optimizers.Adam(learning_rate=lr, beta_1=0.5)\nd_optimizer = tf.optimizers.Adam(learning_rate=lr, beta_1=0.5)\n\nfor epoch in range(epochs):\n    batch_z = tf.random.uniform([batch_size, z_dim], minval=-1., maxval=1.)\n    batch_x = next(db_iter)\n\n    # 1.设定判别训练5次后，生成器训练1次\n    # train D,判别器损失函数，希望能够完全判别，1判别的都是真，0判别的都是假\n    for _ in range(k):\n        with tf.GradientTape() as tape:\n            d_loss = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n        grads = tape.gradient(d_loss, discriminator.trainable_variables)\n        d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n\n    # 2.train G，生成器损失函数，希望生成接近真实照片 1 ，即计算与1的损失\n    with tf.GradientTape() as tape:\n        g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)\n    grads = tape.gradient(g_loss, generator.trainable_variables)\n    g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n\n    if epoch % 100 == 0:\n        print(epoch, 'd_loss', float(d_loss), 'g-loss', float(g_loss))","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:10:30.433794Z","iopub.execute_input":"2023-04-09T11:10:30.434648Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"0 d_loss 1091835648.0 g-loss 674105472.0\n","output_type":"stream"}]}]}